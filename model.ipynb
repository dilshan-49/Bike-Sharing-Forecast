{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9464b4",
   "metadata": {},
   "source": [
    "We will first load the data and scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c12e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_train = pd.read_csv('./dataset/train.csv')\n",
    "df_val = pd.read_csv('./dataset/val.csv')\n",
    "df_test = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "scaler_r = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "scaler_r.fit(df_train[['registered']])\n",
    "scaler_c.fit(df_train[['casual']])\n",
    "\n",
    "\n",
    "df_train['registered_s'] = scaler_r.transform(df_train[['registered']])\n",
    "df_val['registered_s'] = scaler_r.transform(df_val[['registered']])\n",
    "df_test['registered_s'] = scaler_r.transform(df_test[['registered']])\n",
    "\n",
    "df_train['casual_s'] = scaler_c.transform(df_train[['casual']])\n",
    "df_val['casual_s'] = scaler_c.transform(df_val[['casual']])\n",
    "df_test['casual_s'] = scaler_c.transform(df_test[['casual']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b60d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>season</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>registered_s</th>\n",
       "      <th>casual_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.021798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  season  workingday  weathersit  temp   hum  casual  registered  \\\n",
       "0           0       1           0           1  0.24  0.81       3          13   \n",
       "1           1       1           0           1  0.22  0.80       8          32   \n",
       "2           2       1           0           1  0.22  0.80       5          27   \n",
       "3           3       1           0           1  0.24  0.75       3          10   \n",
       "4           4       1           0           1  0.24  0.75       0           1   \n",
       "\n",
       "    day_sin   day_cos  week_sin  week_cos  registered_s  casual_s  \n",
       "0  0.000000  1.000000 -0.781831   0.62349      0.016332  0.008174  \n",
       "1  0.258819  0.965926 -0.781831   0.62349      0.040201  0.021798  \n",
       "2  0.500000  0.866025 -0.781831   0.62349      0.033920  0.013624  \n",
       "3  0.707107  0.707107 -0.781831   0.62349      0.012563  0.008174  \n",
       "4  0.866025  0.500000 -0.781831   0.62349      0.001256  0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65965dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>registered_s</th>\n",
       "      <th>casual_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.021798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  workingday  weathersit  temp   hum   day_sin   day_cos  week_sin  \\\n",
       "0       1           0           1  0.24  0.81  0.000000  1.000000 -0.781831   \n",
       "1       1           0           1  0.22  0.80  0.258819  0.965926 -0.781831   \n",
       "2       1           0           1  0.22  0.80  0.500000  0.866025 -0.781831   \n",
       "3       1           0           1  0.24  0.75  0.707107  0.707107 -0.781831   \n",
       "4       1           0           1  0.24  0.75  0.866025  0.500000 -0.781831   \n",
       "\n",
       "   week_cos  registered_s  casual_s  \n",
       "0   0.62349      0.016332  0.008174  \n",
       "1   0.62349      0.040201  0.021798  \n",
       "2   0.62349      0.033920  0.013624  \n",
       "3   0.62349      0.012563  0.008174  \n",
       "4   0.62349      0.001256  0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "df_val.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "df_test.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af636c",
   "metadata": {},
   "source": [
    "Now Lets create the dataset from the tabular data to work with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e15df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_dataset(data, feature_columns, target_columns, lookback_window, horizon, shift):\n",
    "    \"\"\"\n",
    "    Transforms a time series DataFrame into input-target pairs for a deep learning model.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        feature_columns (list): List of column names to use as input features (X).\n",
    "        target_columns (list): List of column names to use as target variables (Y).\n",
    "        lookback_window (int): The number of past time steps to use as input (X).\n",
    "        horizon (int): The number of future time steps to predict (Y).\n",
    "        shift (int): The number of steps to shift the window for each new sample.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two NumPy arrays, X (inputs) and Y (targets).\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data) - lookback_window - horizon + 1, shift):\n",
    "        # Extract the input features (X) for the current window\n",
    "        x_start = i\n",
    "        x_end = i + lookback_window\n",
    "        X.append(data.iloc[x_start:x_end][feature_columns].values)\n",
    "\n",
    "        # Extract the target variables (Y) for the forecast horizon\n",
    "        y_start = i + lookback_window\n",
    "        y_end = y_start + horizon\n",
    "        Y.append(data.iloc[y_start:y_end][target_columns].values)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define key parameters\n",
    "LOOKBACK_WINDOW = 24  # last 24 hours of data as input\n",
    "FORECAST_HORIZON = 3 # Predict the next 3 hours\n",
    "SHIFT = 1            # Move the window by 1 hour for each new sample\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# The columns model use to learn the patterns.\n",
    "\n",
    "feature_columns = [\n",
    "    'season', 'workingday', 'weathersit', 'temp', 'hum',\n",
    "    'day_sin', 'day_cos', 'week_sin', 'week_cos'\n",
    "]\n",
    "\n",
    "# The columns model will try to predict.\n",
    "target_columns = ['casual_s', 'registered_s']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a75c73",
   "metadata": {},
   "source": [
    "Lets' first create the training dataset and have a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c6e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input (X): (13877, 24, 9)\n",
      "Shape of Target (Y): (13877, 3, 2)\n",
      "\n",
      "--- Example of First Sample ---\n",
      "Input X (first window, all features):\n",
      "[[ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   8.10000000e-01  0.00000000e+00  1.00000000e+00 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  2.58819045e-01  9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  5.00000000e-01  8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  7.07106781e-01  7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  8.66025404e-01  5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  9.65925826e-01  2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  1.00000000e+00  6.12323400e-17 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.00000000e-01\n",
      "   8.60000000e-01  9.65925826e-01 -2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  8.66025404e-01 -5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.20000000e-01\n",
      "   7.60000000e-01  7.07106781e-01 -7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.80000000e-01\n",
      "   7.60000000e-01  5.00000000e-01 -8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.60000000e-01\n",
      "   8.10000000e-01  2.58819045e-01 -9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  4.20000000e-01\n",
      "   7.70000000e-01  1.22464680e-16 -1.00000000e+00 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   7.20000000e-01 -2.58819045e-01 -9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   7.20000000e-01 -5.00000000e-01 -8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.40000000e-01\n",
      "   7.70000000e-01 -7.07106781e-01 -7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.20000000e-01\n",
      "   8.20000000e-01 -8.66025404e-01 -5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.40000000e-01\n",
      "   8.20000000e-01 -9.65925826e-01 -2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  3.00000000e+00  4.20000000e-01\n",
      "   8.80000000e-01 -1.00000000e+00 -1.83697020e-16 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  3.00000000e+00  4.20000000e-01\n",
      "   8.80000000e-01 -9.65925826e-01  2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   8.70000000e-01 -8.66025404e-01  5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   8.70000000e-01 -7.07106781e-01  7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   9.40000000e-01 -5.00000000e-01  8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   8.80000000e-01 -2.58819045e-01  9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]]\n",
      "\n",
      "Target Y (next 3 hours, only targets):\n",
      "[[0.01089918 0.01633166]\n",
      " [0.0027248  0.0201005 ]\n",
      " [0.0027248  0.01005025]]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = create_dataset(df_train, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n",
    "\n",
    "\n",
    "print(f\"Shape of Input (X): {X_train.shape}\")       # shape will be in the following order\n",
    "print(f\"Shape of Target (Y): {Y_train.shape}\")      # [Number of Samples, Window, Number of Features]\n",
    "\n",
    "# Now let's have a look at the first data sample\n",
    "print(\"\\n--- Example of First Sample ---\")\n",
    "print(\"Input X (first window, all features):\")\n",
    "print(X_train[0])\n",
    "print(\"\\nTarget Y (next 3 hours, only targets):\")\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ec7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = create_dataset(df_val, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n",
    "X_test, Y_test = create_dataset(df_test, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020201f",
   "metadata": {},
   "source": [
    "Now Let's create dataloader which will serve the above created data to our models for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e8aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Convert NumPy arrays to PyTorch Tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(Y_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(Y_val)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(Y_test)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e1604",
   "metadata": {},
   "source": [
    "Now let's Design our model.  \n",
    "We will create two models. one solely based on LSTM architecture and another one combining CNN with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a3dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, output_size):\n",
    "        super(LSTMForecaster,self).__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        lstm_out,(h_n,c_n) = self.lstm(x)\n",
    "        out = lstm_out[:,-1,:]  # Getting the output for the final step.\n",
    "        out = self.fc(out)\n",
    "        out = out.view(x.size(0),-1,2) #changing the shape of the output to (batch_size,horizen,targets)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_LSTMForecaster(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, output_size, cnn_filters=32, kernel_size=3):\n",
    "        super(CNN_LSTMForecaster, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.cnn_filters = cnn_filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Input shape: (batch_size, num_features, lookback_window)\n",
    "            nn.Conv1d(\n",
    "                in_channels=num_features, \n",
    "                out_channels=self.cnn_filters, \n",
    "                kernel_size=self.kernel_size,\n",
    "                padding='same'\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_filters,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        #shape of x is (batch_size, lookback_window, num_features)\n",
    "        x = x.permute(0, 2, 1) # for the convolution we need shape of x to be (batch_size, num_features, lookback_window)\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = cnn_out.permute(0, 2, 1) #changing the shape back for LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(cnn_out)\n",
    "        out = lstm_out[:,-1,:]  # Getting the output for the final step.\n",
    "        out = self.fc(out)\n",
    "        out = out.view(x.size(0), -1, 2)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1a35b",
   "metadata": {},
   "source": [
    "Let's initialize the both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883c3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LOOKBACK_WINDOW = 24\n",
    "NUM_FEATURES = 9 # Features we use to predict future\n",
    "FORECAST_HORIZON = 3\n",
    "NUM_TARGETS = 2 # casual and registered\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lstm_model = LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=64,\n",
    "        num_layers=1,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )\n",
    "\n",
    "cnn_lstm_model = CNN_LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=50,\n",
    "        num_layers=2,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9926cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device='cpu', name=''):\n",
    "    \"\"\"\n",
    "    Trains and validates a time series forecasting model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The forecasting model to train.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "        loss_fn (nn.Module): The loss function (e.g., MSELoss).\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        epochs (int): The number of training epochs.\n",
    "        device (str): The device to run the training on ('cpu' or 'cuda').\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "            optimizer.zero_grad() # Reset gradients\n",
    "            \n",
    "            inputs,targets = batch\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * targets.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validating\"):\n",
    "                optimizer.zero_grad() # Reset gradients\n",
    "                \n",
    "                inputs,targets = batch\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device)\n",
    "\n",
    "                output = model(inputs)\n",
    "                \n",
    "                loss = loss_fn(output, targets)\n",
    "                \n",
    "                val_loss += loss.item() * targets.size(0)\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check if current validation loss is the best so far\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            # Save the model state dictionary\n",
    "            best_model_state = model.state_dict()\n",
    "            print(\"Validation loss improved. Saving best model state.\")\n",
    "\n",
    "    torch.save(model.state_dict(),'./models/'+name+'_last.pth') #Save the parameter from last epoch\n",
    "    \n",
    "    if best_model_state:\n",
    "        torch.save(best_model_state, './models/'+name+'_best.pth') # Save the best model\n",
    "        print(\"Training complete. models saved to models/\")\n",
    "    else:\n",
    "        print(\"Training complete. Could not save best model state.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Training: 100%|██████████| 434/434 [00:01<00:00, 265.53it/s]\n",
      "Epoch 1/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 814.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Train Loss: 0.0118, Val Loss: 0.0233\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Training: 100%|██████████| 434/434 [00:01<00:00, 273.48it/s]\n",
      "Epoch 2/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 812.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: Train Loss: 0.0108, Val Loss: 0.0190\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Training: 100%|██████████| 434/434 [00:01<00:00, 306.37it/s]\n",
      "Epoch 3/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 928.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: Train Loss: 0.0086, Val Loss: 0.0131\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Training: 100%|██████████| 434/434 [00:01<00:00, 303.11it/s]\n",
      "Epoch 4/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 992.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: Train Loss: 0.0073, Val Loss: 0.0110\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Training: 100%|██████████| 434/434 [00:01<00:00, 311.08it/s]\n",
      "Epoch 5/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 1045.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: Train Loss: 0.0067, Val Loss: 0.0096\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Training: 100%|██████████| 434/434 [00:01<00:00, 288.05it/s]\n",
      "Epoch 6/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 1056.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: Train Loss: 0.0063, Val Loss: 0.0088\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Training: 100%|██████████| 434/434 [00:01<00:00, 295.25it/s]\n",
      "Epoch 7/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 971.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: Train Loss: 0.0061, Val Loss: 0.0084\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Training: 100%|██████████| 434/434 [00:01<00:00, 293.07it/s]\n",
      "Epoch 8/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 921.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: Train Loss: 0.0058, Val Loss: 0.0081\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Training: 100%|██████████| 434/434 [00:01<00:00, 305.20it/s]\n",
      "Epoch 9/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 931.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: Train Loss: 0.0057, Val Loss: 0.0078\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Training: 100%|██████████| 434/434 [00:01<00:00, 312.45it/s]\n",
      "Epoch 10/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 682.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: Train Loss: 0.0055, Val Loss: 0.0076\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Training: 100%|██████████| 434/434 [00:01<00:00, 305.36it/s]\n",
      "Epoch 11/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 822.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: Train Loss: 0.0054, Val Loss: 0.0074\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Training: 100%|██████████| 434/434 [00:01<00:00, 310.97it/s]\n",
      "Epoch 12/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 861.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: Train Loss: 0.0052, Val Loss: 0.0072\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Training: 100%|██████████| 434/434 [00:01<00:00, 305.15it/s]\n",
      "Epoch 13/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 986.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: Train Loss: 0.0051, Val Loss: 0.0071\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Training: 100%|██████████| 434/434 [00:01<00:00, 284.94it/s]\n",
      "Epoch 14/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 878.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: Train Loss: 0.0050, Val Loss: 0.0070\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Training: 100%|██████████| 434/434 [00:01<00:00, 301.03it/s]\n",
      "Epoch 15/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 868.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: Train Loss: 0.0049, Val Loss: 0.0070\n",
      "Validation loss improved. Saving best model state.\n",
      "Training complete. models saved to models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "train_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=15, \n",
    "    device=device,\n",
    "    name='lstm'\n",
    ")\n",
    "\n",
    "lstm_model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b61a54f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Training: 100%|██████████| 434/434 [00:02<00:00, 196.62it/s]\n",
      "Epoch 1/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 631.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Train Loss: 0.0126, Val Loss: 0.0221\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Training: 100%|██████████| 434/434 [00:02<00:00, 216.52it/s]\n",
      "Epoch 2/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 744.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: Train Loss: 0.0102, Val Loss: 0.0175\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Training: 100%|██████████| 434/434 [00:01<00:00, 218.28it/s]\n",
      "Epoch 3/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 644.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: Train Loss: 0.0079, Val Loss: 0.0102\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Training: 100%|██████████| 434/434 [00:01<00:00, 220.04it/s]\n",
      "Epoch 4/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 627.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: Train Loss: 0.0068, Val Loss: 0.0085\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Training: 100%|██████████| 434/434 [00:02<00:00, 216.43it/s]\n",
      "Epoch 5/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 529.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: Train Loss: 0.0066, Val Loss: 0.0078\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Training: 100%|██████████| 434/434 [00:01<00:00, 222.04it/s]\n",
      "Epoch 6/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 671.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: Train Loss: 0.0064, Val Loss: 0.0075\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Training: 100%|██████████| 434/434 [00:02<00:00, 201.33it/s]\n",
      "Epoch 7/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 601.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: Train Loss: 0.0063, Val Loss: 0.0072\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Training: 100%|██████████| 434/434 [00:02<00:00, 212.81it/s]\n",
      "Epoch 8/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 725.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Training: 100%|██████████| 434/434 [00:01<00:00, 217.83it/s]\n",
      "Epoch 9/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 673.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Training: 100%|██████████| 434/434 [00:02<00:00, 207.67it/s]\n",
      "Epoch 10/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 683.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Training: 100%|██████████| 434/434 [00:02<00:00, 203.70it/s]\n",
      "Epoch 11/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 644.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: Train Loss: 0.0055, Val Loss: 0.0065\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Training: 100%|██████████| 434/434 [00:02<00:00, 206.43it/s]\n",
      "Epoch 12/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 665.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Training: 100%|██████████| 434/434 [00:02<00:00, 207.38it/s]\n",
      "Epoch 13/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 687.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: Train Loss: 0.0051, Val Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Training: 100%|██████████| 434/434 [00:02<00:00, 215.16it/s]\n",
      "Epoch 14/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 721.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: Train Loss: 0.0049, Val Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Training: 100%|██████████| 434/434 [00:02<00:00, 201.15it/s]\n",
      "Epoch 15/15 Validating: 100%|██████████| 54/54 [00:00<00:00, 556.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: Train Loss: 0.0048, Val Loss: 0.0065\n",
      "Training complete. models saved to models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = cnn_lstm_model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "train_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=15,\n",
    "    device=device,\n",
    "    name='cnn_lstm'\n",
    ")\n",
    "\n",
    "cnn_lstm_model=model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1314470",
   "metadata": {},
   "source": [
    "Now we need to evaluate the models on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1836b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, loss_fn, casual_scaler, registered_scaler, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and returns predictions and actual values.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained forecasting model.\n",
    "        test_loader (DataLoader): DataLoader for the test data.\n",
    "        loss_fn (nn.Module): The loss function (e.g., MSELoss).\n",
    "        casual_scaler: The scaler fitted on the casual count training data.\n",
    "        registered_scaler: The scaler fitted on the registered count training data.\n",
    "        device (str): The device to run the evaluation on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing denormalized predictions and actual values.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    all_preds_scaled, all_actuals_scaled = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs,targets = batch\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(output, targets)\n",
    "            test_loss += loss.item() * targets.size(0)\n",
    "            \n",
    "            all_preds_scaled.append(output.cpu().numpy())\n",
    "            all_actuals_scaled.append(targets.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "    print(f\"\\nAverage Test Loss (Scaled MSE): {avg_test_loss:.4f}\")\n",
    "\n",
    "    print('outputs shape: ', output.shape)\n",
    "    print(\"This should be Batch x Horizon x Feature\")\n",
    "    # Concatenate all batches\n",
    "    all_preds_scaled = np.concatenate(all_preds_scaled, axis=0)\n",
    "    all_actuals_scaled = np.concatenate(all_actuals_scaled, axis=0)\n",
    "    print('Concatenated shape: ', all_preds_scaled.shape)\n",
    "    # Denormalize the predictions and actuals\n",
    "    # Note: We need to reshape for the scaler, then reshape back\n",
    "    \n",
    "    # Denormalize Casual predictions and actuals\n",
    "    casual_preds_scaled = all_preds_scaled[:, :, 0]\n",
    "    casual_preds = casual_scaler.inverse_transform(casual_preds_scaled.reshape(-1, 1)).reshape(casual_preds_scaled.shape)\n",
    "    \n",
    "    casual_actuals_scaled = all_actuals_scaled[:, :, 0]\n",
    "    casual_actuals = casual_scaler.inverse_transform(casual_actuals_scaled.reshape(-1, 1)).reshape(casual_actuals_scaled.shape)\n",
    "    \n",
    "    # Denormalize Registered predictions and actuals\n",
    "    registered_preds_scaled = all_preds_scaled[:, :, 1]\n",
    "    registered_preds = registered_scaler.inverse_transform(registered_preds_scaled.reshape(-1, 1)).reshape(registered_preds_scaled.shape)\n",
    "    \n",
    "    registered_actuals_scaled = all_actuals_scaled[:, :, 1]\n",
    "    registered_actuals = registered_scaler.inverse_transform(registered_actuals_scaled.reshape(-1, 1)).reshape(registered_actuals_scaled.shape)\n",
    "    print('After Transform rgistered shape: ', registered_actuals_scaled.shape)\n",
    "    return (casual_preds, registered_preds), (casual_actuals, registered_actuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef5958",
   "metadata": {},
   "source": [
    "Lets Load our saved models from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4575895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'best_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "model_1 = LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=64,\n",
    "        num_layers=1,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )\n",
    "\n",
    "model_2 = CNN_LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=50,\n",
    "        num_layers=2,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )\n",
    "\n",
    "try:\n",
    "    model_1.load_state_dict(torch.load('models/lstm_best.pth', map_location=device))\n",
    "    model_2.load_state_dict(torch.load('models/cnn_lstm_best.pth', map_location=device))\n",
    "    print(\"Successfully loaded 'best_model.pth'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'best_model.pth' not found. Please train the model first.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e5b7826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 54/54 [00:00<00:00, 315.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Test Loss (Scaled MSE): 0.0096\n",
      "outputs shape:  torch.Size([17, 3, 2])\n",
      "This should be Batch x Horizon x Feature\n",
      "Concatenated shape:  (1713, 3, 2)\n",
      "After Transform rgistered shape:  (1713, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_1, actuals_1 = evaluate_model(\n",
    "        model=model_1,\n",
    "        test_loader=test_loader,\n",
    "        loss_fn=nn.MSELoss(),\n",
    "        casual_scaler=scaler_c,\n",
    "        registered_scaler=scaler_r,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd03d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 54/54 [00:00<00:00, 294.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Test Loss (Scaled MSE): 0.0099\n",
      "outputs shape:  torch.Size([17, 3, 2])\n",
      "This should be Batch x Horizon x Feature\n",
      "Concatenated shape:  (1713, 3, 2)\n",
      "After Transform rgistered shape:  (1713, 3)\n"
     ]
    }
   ],
   "source": [
    "preds_2, actuals_2 = evaluate_model(\n",
    "        model=model_2,\n",
    "        test_loader=test_loader,\n",
    "        loss_fn=nn.MSELoss(),\n",
    "        casual_scaler=scaler_c,\n",
    "        registered_scaler=scaler_r,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Reshape to a 1D array for metric calculation\n",
    "casual_preds_flat = preds[0].flatten()\n",
    "casual_actuals_flat = actuals[0].flatten()\n",
    "registered_preds_flat = preds[1].flatten()\n",
    "registered_actuals_flat = actuals[1].flatten()\n",
    "\n",
    "casual_mae = mean_absolute_error(casual_actuals_flat, casual_preds_flat)\n",
    "casual_rmse = np.sqrt(mean_squared_error(casual_actuals_flat, casual_preds_flat))\n",
    "\n",
    "registered_mae = mean_absolute_error(registered_actuals_flat, registered_preds_flat)\n",
    "registered_rmse = np.sqrt(mean_squared_error(registered_actuals_flat, registered_preds_flat))\n",
    "\n",
    "print(\"\\n--- Model Performance on Test Set (Denormalized) ---\")\n",
    "print(f\"Casual Users - MAE: {casual_mae:.2f}, RMSE: {casual_rmse:.2f}\")\n",
    "print(f\"Registered Users - MAE: {registered_mae:.2f}, RMSE: {registered_rmse:.2f}\")\n",
    "\n",
    "# --- 6. Visualize the predictions for a few samples\n",
    "# You can change the index to view different samples\n",
    "plot_predictions(\n",
    "    preds=(casual_preds, registered_preds),\n",
    "    actuals=(casual_actuals, registered_actuals),\n",
    "    sample_index=0\n",
    ")\n",
    "\n",
    "plot_predictions(\n",
    "    preds=(casual_preds, registered_preds),\n",
    "    actuals=(casual_actuals, registered_actuals),\n",
    "    sample_index=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
