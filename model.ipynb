{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9464b4",
   "metadata": {},
   "source": [
    "We will first load the data and scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c12e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_train = pd.read_csv('./dataset/train.csv')\n",
    "df_val = pd.read_csv('./dataset/val.csv')\n",
    "df_test = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "scaler_r = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "scaler_r.fit(df_train[['registered']])\n",
    "scaler_c.fit(df_train[['casual']])\n",
    "\n",
    "\n",
    "df_train['registered_s'] = scaler_r.transform(df_train[['registered']])\n",
    "df_val['registered_s'] = scaler_r.transform(df_val[['registered']])\n",
    "df_test['registered_s'] = scaler_r.transform(df_test[['registered']])\n",
    "\n",
    "df_train['casual_s'] = scaler_c.transform(df_train[['casual']])\n",
    "df_val['casual_s'] = scaler_c.transform(df_val[['casual']])\n",
    "df_test['casual_s'] = scaler_c.transform(df_test[['casual']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1b60d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>season</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>registered_s</th>\n",
       "      <th>casual_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.021798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  season  workingday  weathersit  temp   hum  casual  registered  \\\n",
       "0           0       1           0           1  0.24  0.81       3          13   \n",
       "1           1       1           0           1  0.22  0.80       8          32   \n",
       "2           2       1           0           1  0.22  0.80       5          27   \n",
       "3           3       1           0           1  0.24  0.75       3          10   \n",
       "4           4       1           0           1  0.24  0.75       0           1   \n",
       "\n",
       "    day_sin   day_cos  week_sin  week_cos  registered_s  casual_s  \n",
       "0  0.000000  1.000000 -0.781831   0.62349      0.016332  0.008174  \n",
       "1  0.258819  0.965926 -0.781831   0.62349      0.040201  0.021798  \n",
       "2  0.500000  0.866025 -0.781831   0.62349      0.033920  0.013624  \n",
       "3  0.707107  0.707107 -0.781831   0.62349      0.012563  0.008174  \n",
       "4  0.866025  0.500000 -0.781831   0.62349      0.001256  0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65965dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>registered_s</th>\n",
       "      <th>casual_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.021798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  workingday  weathersit  temp   hum   day_sin   day_cos  week_sin  \\\n",
       "0       1           0           1  0.24  0.81  0.000000  1.000000 -0.781831   \n",
       "1       1           0           1  0.22  0.80  0.258819  0.965926 -0.781831   \n",
       "2       1           0           1  0.22  0.80  0.500000  0.866025 -0.781831   \n",
       "3       1           0           1  0.24  0.75  0.707107  0.707107 -0.781831   \n",
       "4       1           0           1  0.24  0.75  0.866025  0.500000 -0.781831   \n",
       "\n",
       "   week_cos  registered_s  casual_s  \n",
       "0   0.62349      0.016332  0.008174  \n",
       "1   0.62349      0.040201  0.021798  \n",
       "2   0.62349      0.033920  0.013624  \n",
       "3   0.62349      0.012563  0.008174  \n",
       "4   0.62349      0.001256  0.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "df_val.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "df_test.drop(['Unnamed: 0','casual','registered'],axis=1,inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af636c",
   "metadata": {},
   "source": [
    "Now Lets create the dataset from the tabular data to work with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e15df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_dataset(data, feature_columns, target_columns, lookback_window, horizon, shift):\n",
    "    \"\"\"\n",
    "    Transforms a time series DataFrame into input-target pairs for a deep learning model.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        feature_columns (list): List of column names to use as input features (X).\n",
    "        target_columns (list): List of column names to use as target variables (Y).\n",
    "        lookback_window (int): The number of past time steps to use as input (X).\n",
    "        horizon (int): The number of future time steps to predict (Y).\n",
    "        shift (int): The number of steps to shift the window for each new sample.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two NumPy arrays, X (inputs) and Y (targets).\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data) - lookback_window - horizon + 1, shift):\n",
    "        # Extract the input features (X) for the current window\n",
    "        x_start = i\n",
    "        x_end = i + lookback_window\n",
    "        X.append(data.iloc[x_start:x_end][feature_columns].values)\n",
    "\n",
    "        # Extract the target variables (Y) for the forecast horizon\n",
    "        y_start = i + lookback_window\n",
    "        y_end = y_start + horizon\n",
    "        Y.append(data.iloc[y_start:y_end][target_columns].values)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "332e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define key parameters\n",
    "LOOKBACK_WINDOW = 24  # last 24 hours of data as input\n",
    "FORECAST_HORIZON = 3 # Predict the next 3 hours\n",
    "SHIFT = 1            # Move the window by 1 hour for each new sample\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# The columns model use to learn the patterns.\n",
    "\n",
    "feature_columns = [\n",
    "    'season', 'workingday', 'weathersit', 'temp', 'hum',\n",
    "    'day_sin', 'day_cos', 'week_sin', 'week_cos'\n",
    "]\n",
    "\n",
    "# The columns model will try to predict.\n",
    "target_columns = ['casual_s', 'registered_s']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a75c73",
   "metadata": {},
   "source": [
    "Lets' first create the training dataset and have a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0c6e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input (X): (13877, 24, 9)\n",
      "Shape of Target (Y): (13877, 3, 2)\n",
      "\n",
      "--- Example of First Sample ---\n",
      "Input X (first window, all features):\n",
      "[[ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   8.10000000e-01  0.00000000e+00  1.00000000e+00 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  2.58819045e-01  9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  5.00000000e-01  8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  7.07106781e-01  7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  8.66025404e-01  5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  9.65925826e-01  2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.20000000e-01\n",
      "   8.00000000e-01  1.00000000e+00  6.12323400e-17 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.00000000e-01\n",
      "   8.60000000e-01  9.65925826e-01 -2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  2.40000000e-01\n",
      "   7.50000000e-01  8.66025404e-01 -5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.20000000e-01\n",
      "   7.60000000e-01  7.07106781e-01 -7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.80000000e-01\n",
      "   7.60000000e-01  5.00000000e-01 -8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  3.60000000e-01\n",
      "   8.10000000e-01  2.58819045e-01 -9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  4.20000000e-01\n",
      "   7.70000000e-01  1.22464680e-16 -1.00000000e+00 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   7.20000000e-01 -2.58819045e-01 -9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   7.20000000e-01 -5.00000000e-01 -8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.40000000e-01\n",
      "   7.70000000e-01 -7.07106781e-01 -7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.20000000e-01\n",
      "   8.20000000e-01 -8.66025404e-01 -5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.40000000e-01\n",
      "   8.20000000e-01 -9.65925826e-01 -2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  3.00000000e+00  4.20000000e-01\n",
      "   8.80000000e-01 -1.00000000e+00 -1.83697020e-16 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  3.00000000e+00  4.20000000e-01\n",
      "   8.80000000e-01 -9.65925826e-01  2.58819045e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   8.70000000e-01 -8.66025404e-01  5.00000000e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   8.70000000e-01 -7.07106781e-01  7.07106781e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.00000000e-01\n",
      "   9.40000000e-01 -5.00000000e-01  8.66025404e-01 -7.81831482e-01\n",
      "   6.23489802e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.00000000e+00  4.60000000e-01\n",
      "   8.80000000e-01 -2.58819045e-01  9.65925826e-01 -7.81831482e-01\n",
      "   6.23489802e-01]]\n",
      "\n",
      "Target Y (next 3 hours, only targets):\n",
      "[[0.01089918 0.01633166]\n",
      " [0.0027248  0.0201005 ]\n",
      " [0.0027248  0.01005025]]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = create_dataset(df_train, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n",
    "\n",
    "\n",
    "print(f\"Shape of Input (X): {X_train.shape}\")       # shape will be in the following order\n",
    "print(f\"Shape of Target (Y): {Y_train.shape}\")      # [Number of Samples, Window, Number of Features]\n",
    "\n",
    "# Now let's have a look at the first data sample\n",
    "print(\"\\n--- Example of First Sample ---\")\n",
    "print(\"Input X (first window, all features):\")\n",
    "print(X_train[0])\n",
    "print(\"\\nTarget Y (next 3 hours, only targets):\")\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ec7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = create_dataset(df_val, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n",
    "X_test, Y_test = create_dataset(df_test, feature_columns, target_columns, LOOKBACK_WINDOW, FORECAST_HORIZON, SHIFT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020201f",
   "metadata": {},
   "source": [
    "Now Let's create dataloader which will serve the above created data to our models for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28e8aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Convert NumPy arrays to PyTorch Tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(Y_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(Y_val)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(Y_test)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e1604",
   "metadata": {},
   "source": [
    "Now let's Design our model.  \n",
    "We will create two models. one solely based on LSTM architecture and another one combining CNN with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33a3dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, output_size):\n",
    "        super(LSTMForecaster,self).__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        lstm_out,(h_n,c_n) = self.lstm(x)\n",
    "        out = lstm_out[:,-1,:]  # Getting the output for the final step.\n",
    "        out = self.fc(out)\n",
    "        out = out.view(x.size(0),-1,2) #changing the shape of the output to (batch_size,horizen,targets)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_LSTMForecaster(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, output_size, cnn_filters=32, kernel_size=3):\n",
    "        super(CNN_LSTMForecaster, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.cnn_filters = cnn_filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Input shape: (batch_size, num_features, lookback_window)\n",
    "            nn.Conv1d(\n",
    "                in_channels=num_features, \n",
    "                out_channels=self.cnn_filters, \n",
    "                kernel_size=self.kernel_size,\n",
    "                padding='same'\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_filters,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        #shape of x is (batch_size, lookback_window, num_features)\n",
    "        x = x.permute(0, 2, 1) # for the convolution we need shape of x to be (batch_size, num_features, lookback_window)\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = cnn_out.permute(0, 2, 1) #changing the shape back for LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(cnn_out)\n",
    "        out = lstm_out[:,-1,:]  # Getting the output for the final step.\n",
    "        out = self.fc(out)\n",
    "        out = out.view(x.size(0), -1, 2)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1a35b",
   "metadata": {},
   "source": [
    "Let's initialize the both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "883c3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LOOKBACK_WINDOW = 24\n",
    "NUM_FEATURES = 9 # Features we use to predict future\n",
    "FORECAST_HORIZON = 3\n",
    "NUM_TARGETS = 2 # casual and registered\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lstm_model = LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=64,\n",
    "        num_layers=1,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )\n",
    "\n",
    "cnn_lstm_model = CNN_LSTMForecaster(\n",
    "        num_features=NUM_FEATURES,\n",
    "        hidden_size=50,\n",
    "        num_layers=2,\n",
    "        output_size=FORECAST_HORIZON * NUM_TARGETS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9926cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device='cpu', name=''):\n",
    "    \"\"\"\n",
    "    Trains and validates a time series forecasting model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The forecasting model to train.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to use for training.\n",
    "        loss_fn (nn.Module): The loss function (e.g., MSELoss).\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        epochs (int): The number of training epochs.\n",
    "        device (str): The device to run the training on ('cpu' or 'cuda').\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "            optimizer.zero_grad() # Reset gradients\n",
    "            \n",
    "            inputs,targets = batch\n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * targets.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validating\"):\n",
    "                optimizer.zero_grad() # Reset gradients\n",
    "                \n",
    "                inputs,targets = batch\n",
    "                inputs=inputs.to(device)\n",
    "                targets=targets.to(device)\n",
    "\n",
    "                output = model(inputs)\n",
    "                \n",
    "                loss = loss_fn(output, targets)\n",
    "                \n",
    "                val_loss += loss.item() * targets.size(0)\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check if current validation loss is the best so far\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            # Save the model state dictionary\n",
    "            best_model_state = model.state_dict()\n",
    "            print(\"Validation loss improved. Saving best model state.\")\n",
    "\n",
    "    torch.save(model.state_dict(),'./models/'+name+'_last.pth') #Save the parameter from last epoch\n",
    "    \n",
    "    if best_model_state:\n",
    "        torch.save(best_model_state, './models/'+name+'_best.pth') # Save the best model\n",
    "        print(\"Training complete. models saved to models/\")\n",
    "    else:\n",
    "        print(\"Training complete. Could not save best model state.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42af329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 434/434 [00:01<00:00, 243.28it/s]\n",
      "Epoch 1/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 765.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 0.0051, Val Loss: 0.0069\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 434/434 [00:01<00:00, 286.98it/s]\n",
      "Epoch 2/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 591.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 0.0051, Val Loss: 0.0068\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 434/434 [00:01<00:00, 308.60it/s]\n",
      "Epoch 3/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 867.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.0050, Val Loss: 0.0068\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 434/434 [00:01<00:00, 294.71it/s]\n",
      "Epoch 4/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 839.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.0049, Val Loss: 0.0067\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 434/434 [00:01<00:00, 289.31it/s]\n",
      "Epoch 5/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 846.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.0049, Val Loss: 0.0067\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 434/434 [00:01<00:00, 305.65it/s]\n",
      "Epoch 6/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 813.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.0048, Val Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 434/434 [00:01<00:00, 303.52it/s]\n",
      "Epoch 7/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 803.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.0047, Val Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 434/434 [00:01<00:00, 291.45it/s]\n",
      "Epoch 8/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 802.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 0.0046, Val Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Training: 100%|██████████| 434/434 [00:01<00:00, 299.73it/s]\n",
      "Epoch 9/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 873.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 0.0045, Val Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Training: 100%|██████████| 434/434 [00:01<00:00, 303.74it/s]\n",
      "Epoch 10/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 879.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 0.0044, Val Loss: 0.0068\n",
      "Training complete. models saved to models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "train_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10, \n",
    "    device=device,\n",
    "    name='lstm'\n",
    ")\n",
    "\n",
    "lstm_model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b61a54f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 434/434 [00:02<00:00, 183.89it/s]\n",
      "Epoch 1/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 635.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 0.0051, Val Loss: 0.0065\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 434/434 [00:02<00:00, 200.62it/s]\n",
      "Epoch 2/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 679.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 0.0049, Val Loss: 0.0065\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 434/434 [00:02<00:00, 209.54it/s]\n",
      "Epoch 3/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 716.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.0047, Val Loss: 0.0064\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 434/434 [00:02<00:00, 207.63it/s]\n",
      "Epoch 4/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 499.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.0046, Val Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 434/434 [00:02<00:00, 214.91it/s]\n",
      "Epoch 5/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 526.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.0045, Val Loss: 0.0063\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 434/434 [00:02<00:00, 208.97it/s]\n",
      "Epoch 6/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 629.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.0044, Val Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 434/434 [00:02<00:00, 206.90it/s]\n",
      "Epoch 7/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 632.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.0042, Val Loss: 0.0063\n",
      "Validation loss improved. Saving best model state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 434/434 [00:02<00:00, 207.68it/s]\n",
      "Epoch 8/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 594.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 0.0041, Val Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Training: 100%|██████████| 434/434 [00:02<00:00, 208.79it/s]\n",
      "Epoch 9/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 678.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 0.0040, Val Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Training: 100%|██████████| 434/434 [00:02<00:00, 211.29it/s]\n",
      "Epoch 10/10 Validating: 100%|██████████| 54/54 [00:00<00:00, 582.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 0.0039, Val Loss: 0.0064\n",
      "Training complete. models saved to models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = cnn_lstm_model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "train_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10, # You can set this to a higher number\n",
    "    device=device,\n",
    "    name='cnn_lstm'\n",
    ")\n",
    "\n",
    "cnn_lstm_model=model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
